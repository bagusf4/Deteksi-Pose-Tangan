{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd9a9e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are the functionality you can select from\n",
      "1. Switch Window\n",
      "2. Space\n",
      "3. Enter\n",
      "4. Screenshot\n",
      "5. Volume Up\n",
      "6. Volume Down\n",
      "7. Backspace\n",
      "8. Brightness Up\n",
      "9. Scroll Up\n",
      "10. Scroll Down\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "mpHands = mp.solutions.hands\n",
    "mpDraw = mp.solutions.drawing_utils\n",
    "\n",
    "label = []\n",
    "\n",
    "#From MEDIAPIPE DOCS\n",
    "\n",
    "class HandDetector:\n",
    "    def __init__(self, max_num_hands=3 , min_detection_confidence=0.7, min_tracking_confidence=0.8):\n",
    "\n",
    "        self.tipIds = [4, 8, 12, 16, 20]\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.maxHands = max_num_hands\n",
    "        self.hands = mpHands.Hands(max_num_hands=max_num_hands, min_detection_confidence=min_detection_confidence,\n",
    "                                   min_tracking_confidence=min_tracking_confidence)\n",
    "    \n",
    "    #From MEDIAPIPE DOCS\n",
    "    def findHandLandMarks(self, image, handNumber=0, draw=False):\n",
    "        originalImage = image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # mediapipe needs RGB\n",
    "        results = self.hands.process(image)\n",
    "        landMarkList = []\n",
    "\n",
    "        if results.multi_handedness:\n",
    "            label = results.multi_handedness[handNumber].classification[0].label  # label gives if hand is left or right\n",
    "            # account for inversion in webcams\n",
    "            if label == \"Left\":\n",
    "                label = \"Right\"\n",
    "            elif label == \"Right\":\n",
    "                label = \"Left\"\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand = results.multi_hand_landmarks[handNumber]  # results.multi_hand_landmarks returns landMarks for all the hands\n",
    "\n",
    "            for id, landMark in enumerate(hand.landmark):\n",
    "                # landMark holds x,y,z ratios of single landmark\n",
    "                imgH, imgW, imgC = originalImage.shape  # height, width, channel for image\n",
    "                xPos, yPos = int(landMark.x * imgW), int(landMark.y * imgH)\n",
    "                landMarkList.append([id, xPos, yPos, label])\n",
    "\n",
    "            if draw:\n",
    "                mpDraw.draw_landmarks(originalImage, hand, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "        return landMarkList\n",
    "    \n",
    "    #Taken from Murtaza Robotics Lab for moving the cursor\n",
    "    def findHands(self, img, draw=True):\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "        # print(results.multi_hand_landmarks)\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms,\n",
    "                                               self.mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    #Taken from Murtaza Robotics Lab for moving the cursor\n",
    "    def findDistance(self, p1, p2, img, draw=True,r=15, t=3):\n",
    "        x1, y1 = self.lmList[p1][1:]\n",
    "        x2, y2 = self.lmList[p2][1:]\n",
    "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "        if draw:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), (255, 0, 255), t)\n",
    "            cv2.circle(img, (x1, y1), r, (255, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x2, y2), r, (255, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (cx, cy), r, (0, 0, 255), cv2.FILLED)\n",
    "        length = math.hypot(x2 - x1, y2 - y1)\n",
    "\n",
    "        return length, img, [x1, y1, x2, y2, cx, cy]\n",
    "    \n",
    "    #Taken from Murtaza Robotics Lab for moving the cursor\n",
    "    def findPosition(self, img, handNo=0, draw=True):\n",
    "        xList = []\n",
    "        yList = []\n",
    "        bbox = []\n",
    "        self.lmList = []\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            myHand = self.results.multi_hand_landmarks[handNo]\n",
    "            for id, lm in enumerate(myHand.landmark):\n",
    "                # print(id, lm)\n",
    "                h, w, c = img.shape\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                xList.append(cx)\n",
    "                yList.append(cy)\n",
    "                # print(id, cx, cy)\n",
    "                self.lmList.append([id, cx, cy])\n",
    "                if draw:\n",
    "                    cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\n",
    "\n",
    "            xmin, xmax = min(xList), max(xList)\n",
    "            ymin, ymax = min(yList), max(yList)\n",
    "            bbox = xmin, ymin, xmax, ymax\n",
    "\n",
    "            if draw:\n",
    "                cv2.rectangle(img, (xmin - 20, ymin - 20), (xmax + 20, ymax + 20),\n",
    "                              (0, 255, 0), 2)\n",
    "\n",
    "        return self.lmList, bbox\n",
    "    \n",
    "    #Taken from Murtaza Robotics Lab for moving the cursor\n",
    "    def fingersUp(self):\n",
    "        fingers = []\n",
    "        # Thumb\n",
    "        if self.lmList[self.tipIds[0]][1] > self.lmList[self.tipIds[0] - 1][1]:\n",
    "            fingers.append(1)\n",
    "        else:\n",
    "            fingers.append(0)\n",
    "\n",
    "        # Fingers\n",
    "        for id in range(1, 5):\n",
    "\n",
    "            if self.lmList[self.tipIds[id]][2] < self.lmList[self.tipIds[id] - 2][2]:\n",
    "                fingers.append(1)\n",
    "            else:\n",
    "                fingers.append(0)\n",
    "\n",
    "        return fingers\n",
    "\n",
    "import cv2\n",
    "import pyautogui\n",
    "import time\n",
    "from pynput.mouse import Button, Controller\n",
    "import autopy\n",
    "import numpy as np\n",
    "from mss import mss\n",
    "from PIL import Image\n",
    "import screen_brightness_control as sbc\n",
    "\n",
    "handDetector = HandDetector(min_detection_confidence=0.7)\n",
    "webcamFeed = cv2.VideoCapture(0)\n",
    "\n",
    "mouse = Controller()\n",
    "\n",
    "pyautogui.FAILSAFE = False\n",
    "\n",
    "# Declaration of Right Hand Landmarks\n",
    "right_thumb = 0\n",
    "right_index = 0\n",
    "right_middle = 0\n",
    "right_ring = 0\n",
    "right_little = 0\n",
    "\n",
    "# Declaration of Right Hand Landmarks\n",
    "\n",
    "left_thumb = 0\n",
    "left_index = 0\n",
    "left_middle = 0\n",
    "left_ring = 0\n",
    "left_little = 0\n",
    "\n",
    "wCam, hCam = 640, 480\n",
    "frameR = 100  # Frame Reduction\n",
    "smoothening = 5\n",
    "\n",
    "pTime = 0\n",
    "plocX, plocY = 0, 0\n",
    "clocX, clocY = 0, 0\n",
    "\n",
    "############################################################################\n",
    "\n",
    "\n",
    "def showImage(imgName):\n",
    "    img = Image.open(imgName)\n",
    "    img.show()\n",
    "\n",
    "\n",
    "working1 = False\n",
    "working2 = False\n",
    "working3 = False\n",
    "working4 = False\n",
    "working5 = False\n",
    "working6 = False\n",
    "working7 = False\n",
    "working8 = False\n",
    "\n",
    "print(\"Below are the functionality you can select from\")\n",
    "time.sleep(1)\n",
    "print(\"1. Switch Window\")\n",
    "time.sleep(0.5)\n",
    "print(\"2. Space\")\n",
    "time.sleep(0.5)\n",
    "print(\"3. Enter\")\n",
    "time.sleep(0.5)\n",
    "print(\"4. Screenshot\")\n",
    "time.sleep(0.5)\n",
    "print(\"5. Volume Up\")\n",
    "time.sleep(0.5)\n",
    "print(\"6. Volume Down\")\n",
    "time.sleep(0.5)\n",
    "print(\"7. Backspace\")\n",
    "time.sleep(0.5)\n",
    "print(\"8. Brightness Up\")\n",
    "time.sleep(0.5)\n",
    "print(\"9. Scroll Up\")\n",
    "time.sleep(0.5)\n",
    "print(\"10. Scroll Down\")\n",
    "time.sleep(1.0)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "##################################################\n",
    "\n",
    "\n",
    "def backspace():\n",
    "    cv2.putText(image, \"Backspace\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # BACKSPACE\n",
    "    pyautogui.hotkey('backspace')\n",
    "    time.sleep(0.2)\n",
    "\n",
    "\n",
    "def volumeUp():\n",
    "    cv2.putText(image, \"Volume Increase\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # VOLUME UP\n",
    "    pyautogui.press('volumeup')\n",
    "\n",
    "\n",
    "def volumeDown():\n",
    "    cv2.putText(image, \"Volume Down\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # VOLUME DOWN\n",
    "    pyautogui.press('volumedown')\n",
    "\n",
    "\n",
    "def windowSwitch():\n",
    "    cv2.putText(image, \"WINDOW SWITCH\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # SWITCH WINDOW\n",
    "    pyautogui.hotkey('ctrl', 'alt', 'tab')\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "def screenshot():\n",
    "    cv2.putText(image, \"MOUSE LEFT CLICK\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # SCREENSHOT\n",
    "    filename = mss().shot()\n",
    "    print(filename)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "def enter():\n",
    "    cv2.putText(image, \"ENTER\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # ENTER\n",
    "    pyautogui.press('enter')\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "def space() :\n",
    "    cv2.putText(image, \"SPACE\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # SPACE\n",
    "    pyautogui.press('space')\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "def brightnessUp():\n",
    "    cv2.putText(image, \"BRIGHTNESS UP\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # BRIGHTNESS UP\n",
    "    current_brightness = sbc.get_brightness()\n",
    "    print(current_brightness)\n",
    "    new_brightness = sbc.set_brightness(current_brightness + 5)\n",
    "    print(new_brightness)\n",
    "    \n",
    "def brightnessDown():\n",
    "    cv2.putText(image, \"BRIGHTNESS Down\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # BRIGHTNESS Down\n",
    "    curr_brightness = sbc.get_brightness()\n",
    "    print(curr_brightness)\n",
    "    baru_brightness = sbc.set_brightness(curr_brightness - 5)\n",
    "    print(baru_brightness)\n",
    "    \n",
    "def scrollUp():\n",
    "    cv2.putText(image, \"Scroll Up\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # scroll UP\n",
    "    pyautogui.scroll(50)\n",
    "\n",
    "def scrollDown():\n",
    "    cv2.putText(image, \"Scroll Down\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # scroll UP\n",
    "    pyautogui.scroll(-150)\n",
    "    \n",
    "def tutup():\n",
    "    cv2.putText(image, \"Close\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # scroll UP\n",
    "    pyautogui.typewrite('q')\n",
    "    \n",
    "functions_dict = {\n",
    "    '1': windowSwitch,\n",
    "    '2': space,\n",
    "    '3': enter,\n",
    "    '4': screenshot,\n",
    "    '5': volumeUp,\n",
    "    '6': volumeDown,\n",
    "    '7': backspace,\n",
    "    '8': brightnessUp,\n",
    "    '9': scrollUp,\n",
    "    '10': scrollDown,\n",
    "    '11': brightnessDown,\n",
    "    '12': tutup\n",
    "}\n",
    "#################################################\n",
    "\n",
    "while True:\n",
    "    status, image = webcamFeed.read()\n",
    "    # webcamFeed.set(3, wCam)\n",
    "    # webcamFeed.set(4, hCam)\n",
    "    wScr, hScr = autopy.screen.size()\n",
    "    handLandmarks = handDetector.findHandLandMarks(image=image, draw=True)\n",
    "    count = 0\n",
    "\n",
    "    if len(handLandmarks) != 0:\n",
    "\n",
    "        right_thumb = True if (handLandmarks[4][3] == \"Right\" and handLandmarks[4][1] > handLandmarks[3][1]) else False\n",
    "        right_index = True if (handLandmarks[4][3] == \"Right\" and handLandmarks[8][2] < handLandmarks[6][2]) else False\n",
    "        right_middle = True if (\n",
    "                handLandmarks[4][3] == \"Right\" and handLandmarks[12][2] < handLandmarks[10][2]) else False\n",
    "        right_ring = True if (handLandmarks[4][3] == \"Right\" and handLandmarks[16][2] < handLandmarks[14][2]) else False\n",
    "        right_little = True if (\n",
    "                handLandmarks[4][3] == \"Right\" and handLandmarks[20][2] < handLandmarks[18][2]) else False\n",
    "\n",
    "        left_thumb = True if (handLandmarks[4][3] == \"Left\" and handLandmarks[8][2] < handLandmarks[6][2]) else False\n",
    "        left_index = True if (handLandmarks[4][3] == \"Left\" and handLandmarks[8][2] < handLandmarks[6][2]) else False\n",
    "        left_middle = True if (handLandmarks[4][3] == \"Left\" and handLandmarks[12][2] < handLandmarks[10][2]) else False\n",
    "        left_ring = True if (handLandmarks[4][3] == \"Left\" and handLandmarks[16][2] < handLandmarks[14][2]) else False\n",
    "        left_little = True if (handLandmarks[4][3] == \"Left\" and handLandmarks[20][2] < handLandmarks[18][2]) else False\n",
    "\n",
    "        if right_thumb and right_little and not right_middle and not right_ring and not right_index:\n",
    "            # volDown\n",
    "            functions_dict['6']()\n",
    "            \n",
    "        elif not left_middle and not left_index and not left_little and not left_thumb and not left_ring:\n",
    "            functions_dict['12']()\n",
    "\n",
    "        elif right_thumb and not right_index and not right_middle and not right_ring and not right_little:\n",
    "            functions_dict['8']()\n",
    "            \n",
    "        elif right_little and not right_index and not right_middle and not right_ring and not right_thumb:\n",
    "            functions_dict['11']()\n",
    "\n",
    "        elif left_thumb and left_index and not left_little and not left_ring and not left_middle:\n",
    "            functions_dict['2']()\n",
    "\n",
    "        elif right_thumb and right_index and right_little and right_middle and right_ring:\n",
    "            functions_dict['7']()\n",
    "\n",
    "        elif left_index and left_middle and not left_ring and not left_little and left_thumb:\n",
    "            functions_dict['1']()\n",
    "\n",
    "        elif right_index and right_middle and right_ring and not right_little and not right_thumb:\n",
    "            functions_dict['4']()\n",
    "\n",
    "        elif right_thumb and right_index and right_little and not right_middle and not right_ring:\n",
    "            functions_dict['5']()\n",
    "\n",
    "        elif left_thumb and left_index and left_middle and left_ring and left_little:\n",
    "            functions_dict['3']()\n",
    "            \n",
    "        elif left_thumb and left_index and  left_little and not left_middle and not left_ring:\n",
    "            functions_dict['10']()\n",
    "            \n",
    "            \n",
    "        elif left_little and not left_thumb and not left_index and not left_middle and not left_ring:\n",
    "            functions_dict['9']()\n",
    "            \n",
    "        \n",
    "\n",
    "    image = handDetector.findHands(image)\n",
    "    lmList, bbox = handDetector.findPosition(image)\n",
    "\n",
    "    if len(lmList) != 0:\n",
    "        x1, y1 = lmList[8][1:]\n",
    "        x2, y2 = lmList[12][1:]\n",
    "    cv2.rectangle(image, (frameR, frameR), (wCam - frameR, hCam - frameR), (255, 0, 255), 2)\n",
    "\n",
    "    if right_index and not right_middle and not right_ring and not right_little and not right_thumb:\n",
    "        cv2.putText(image, \"MOVE CURSOR\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # MOVE CURSOR\n",
    "        x3 = np.interp(x1, (frameR, wCam - frameR), (0, wScr))\n",
    "        y3 = np.interp(y1, (frameR, hCam - frameR), (0, hScr))\n",
    "        clocX = plocX + (x3 - plocX) / smoothening\n",
    "        clocY = plocY + (y3 - plocY) / smoothening\n",
    "\n",
    "        autopy.mouse.move(wScr - clocX, clocY)\n",
    "        cv2.circle(image, (x1, y1), 15, (255, 0, 255), cv2.FILLED)\n",
    "        plocX, plocY = clocX, clocY\n",
    "\n",
    "    if right_index and right_middle and not right_ring and not right_little and not right_thumb:\n",
    "        cv2.putText(image, \"Click\", (45, 375), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 5)  # CLICK\n",
    "        length, img, lineInfo = handDetector.findDistance(10, 14, image + 5000)\n",
    "        print(length)\n",
    "        if length < 50:\n",
    "            cv2.circle(img, (lineInfo[4], lineInfo[5]),\n",
    "                       15, (0, 255, 0), cv2.FILLED)\n",
    "            autopy.mouse.click()\n",
    "   \n",
    "    cv2.imshow(\"Webcam\", image)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "webcamFeed.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
